# DetectionFusion GT Rectification Configuration - Balanced Mode
# This configuration balances precision and recall for moderate error detection

gt_rectification:
  # Mode configuration
  mode: "minimize_error"  # Use conservative mode with balanced parameters
  
  # Directory paths
  labels_dir: "labels"
  gt_dir: "labels/GT"
  images_dir: "images"
  output_dir: "rectified_dataset_balanced"
  
  # Threshold parameters (balanced - moderate thresholds)
  confidence_threshold: 0.5        # Medium confidence threshold
  iou_threshold: 0.5               # Standard IoU threshold
  min_strategy_agreement: 0.7      # 70% strategy agreement
  consensus_threshold: 0.75        # Moderate consensus required
  
  # Strategy selection (balanced subset - proven strategies)
  strategies:
    - "weighted_vote"
    - "bayesian"
    - "consensus_ranking"
    - "majority_vote_2"
    - "majority_vote_3"
    - "affirmative_nms"
    - "confidence_weighted_nms"
    - "dbscan"
    - "soft_voting"
    - "adaptive_threshold"
    - "high_confidence_first"
  
  # Error detection parameters
  error_detection:
    min_confidence_gap: 0.2        # Moderate confidence gap
    min_disagreement_ratio: 0.6    # Moderate disagreement required
    require_multiple_strategies: true  # Multiple strategies should agree
    detect_edge_cases: false       # Skip borderline cases
    
  # Output configuration
  output:
    include_most_correct: 40       # Moderate number of reference images
    include_most_incorrect: 60     # Moderate number of flagged images
    create_analysis_files: true
    create_summary_report: true
    copy_images: true
    
  # Analysis parameters
  analysis:
    confidence_bins: 8             # Moderate detail in confidence analysis
    spatial_analysis: true         # Include spatial analysis
    size_analysis: true           # Include size analysis
    class_analysis: false         # Skip per-class analysis
    error_categories:
      - "missing_in_gt"
      - "extra_in_gt"
      - "classification_error"
      - "localization_error"

# Evaluation settings for validation
evaluation:
  confidence_threshold: 0.1
  iou_thresholds:
    - 0.5
    - 0.75
  metrics:
    - "precision"
    - "recall"
    - "f1_score"
    - "map_50"

# Visualization settings
visualization:
  generate_plots: true            # Generate key plots
  figure_size: [12, 7]
  dpi: 200
  style: "seaborn"
  color_palette: "Set2"
  plot_types:
    - "confidence_distribution"
    - "error_category_breakdown"
    - "strategy_agreement_matrix"